{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, such as requests, for making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for making API calls\n",
    "#%pip install requests\n",
    "#%pip install pandas\n",
    "#%pip install datetime\n",
    "#%pip install os\n",
    "#%pip install cudf\n",
    "#%pip install cupy\n",
    "#%pip install openpyxl\n",
    "#%pip install textblob\n",
    "#%pip install transformers\n",
    "#%pip install torch\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define API Key\n",
    "Define the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Eodhd = \"66c0aeb1357b15.87356825\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of tickets under an exchange\n",
    "Define a function get list of tickers under an exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Code                                               Name      Country  \\\n",
      "0    1ARKG   LS ARK Genomic Revolution Tracker ETP Securities  Netherlands   \n",
      "1    1ARKK                                  ARK INNOVATION 1X  Netherlands   \n",
      "2    1ARKW                LS ARK NextGen Internet Tracker ETP  Netherlands   \n",
      "3     2BRK                                  2x Long Berkshire  Netherlands   \n",
      "4     2HCA  iShares MSCI World Health Care Sector ESG UCIT...  Netherlands   \n",
      "..     ...                                                ...          ...   \n",
      "429   WSRI  Amundi MSCI World SRI Climate Net Zero Ambitio...  Netherlands   \n",
      "430   WTCH  SPDR® MSCI World Technology UCITS ETF USD Acc EUR  Netherlands   \n",
      "431   WTEL  SPDR® MSCI World Communication Services UCITS ...  Netherlands   \n",
      "432   WUTI       SPDR® MSCI World Utilities UCITS ETF USD Acc  Netherlands   \n",
      "433   WVAL                    SPDR MSCI World Value UCITS ETF  Netherlands   \n",
      "\n",
      "    Exchange Currency Type          Isin  \n",
      "0         AS      EUR  ETF  XS2399368062  \n",
      "1         AS      EUR  ETF  XS2399369037  \n",
      "2         AS      EUR  ETF  XS2399368575  \n",
      "3         AS      EUR  ETF  XS2399369110  \n",
      "4         AS      EUR  ETF          None  \n",
      "..       ...      ...  ...           ...  \n",
      "429       AS      EUR  ETF  IE000Y77LGG9  \n",
      "430       AS      EUR  ETF  IE00BYTRRD19  \n",
      "431       AS      EUR  ETF  IE00BYTRRG40  \n",
      "432       AS      EUR  ETF  IE00BYTRRH56  \n",
      "433       AS      EUR  ETF  IE00BJXRT813  \n",
      "\n",
      "[434 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def fetch_exchanges_list(api_token=API_Eodhd, filtered_columns=[\"Name\", \"Code\", \"Country\", \"Currency\"]):\n",
    "    \"\"\"\n",
    "    Fetch the list of exchanges from the EODHD API and return it as a filtered Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        api_token (str): Your API token for authentication.\n",
    "        filtered_columns (list): List of columns to include in the output DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The exchange list as a Pandas DataFrame with selected columns.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/exchanges-list/?api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Convert JSON to Pandas DataFrame\n",
    "    exchanges_df = pd.DataFrame(response)\n",
    "    \n",
    "    # Filter columns if specified\n",
    "    if filtered_columns:\n",
    "\n",
    "        exchanges_df = exchanges_df[filtered_columns]\n",
    "    \n",
    "    return exchanges_df\n",
    "\n",
    "def fetch_exchange_symbols(exchange_code, api_token=API_Eodhd, filtered_columns=None):\n",
    "    \"\"\"\n",
    "    Fetch the symbol list for a given exchange from the EODHD API and return it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        exchange_code (str): The code of the exchange (e.g., \"US\").\n",
    "        api_token (str): Your API token for authentication.\n",
    "        filtered_columns (list): List of columns to include in the output DataFrame (optional).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The symbol list as a Pandas DataFrame with selected columns.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/exchange-symbol-list/{exchange_code}?api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Convert JSON to Pandas DataFrame\n",
    "    symbols_df = pd.DataFrame(response)\n",
    "    \n",
    "    # Filter columns if specified\n",
    "    if filtered_columns:\n",
    "        symbols_df = symbols_df[filtered_columns]\n",
    "    \n",
    "    return symbols_df\n",
    "\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get historical market data\n",
    "uses a function to get historical market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  adjusted_close\n",
      "0    2023-01-03           13.88\n",
      "1    2023-01-04           14.11\n",
      "2    2023-01-05           14.14\n",
      "3    2023-01-06           15.65\n",
      "4    2023-01-09           15.65\n",
      "..          ...             ...\n",
      "182  2023-09-25            8.41\n",
      "183  2023-09-26            8.25\n",
      "184  2023-09-27            8.23\n",
      "185  2023-09-28            8.25\n",
      "186  2023-09-29            8.00\n",
      "\n",
      "[187 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def Fetch_historical_price(stock1, begin_date, end_date, period, api_token=API_Eodhd, columns=[\"adjusted_close\"]):\n",
    "    \"\"\"\n",
    "    Fetch stock data from the EODHD API and return it as a filtered Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock1 (str): The stock symbol (e.g., \"MCD.US\").\n",
    "        begin_date (str): The start date in \"YYYY-MM-DD\" format.\n",
    "        end_date (str): The end date in \"YYYY-MM-DD\" format.\n",
    "        period (str): The period (e.g., \"d\" for daily).\n",
    "        api_token (str): Your API token for authentication.\n",
    "        columns (list): List of columns to filter (e.g., ['open', 'close','adjusted_close',volume]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered stock data as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/eod/{stock1}?from={begin_date}&to={end_date}&period={period}&api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Convert JSON to Pandas DataFrame\n",
    "    pandas_df = pd.DataFrame(response)\n",
    "    \n",
    "    # Filter columns if specified\n",
    "    if columns:\n",
    "       filtered_columns = ['date'] + columns\n",
    "       pandas_df = pandas_df[filtered_columns]\n",
    "    \n",
    "    return pandas_df\n",
    "\n",
    "\n",
    "ZYXI = Fetch_historical_price(\"ZYXI.US\", \"2023-01-01\", \"2023-10-01\", \"d\" )\n",
    "print(ZYXI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting financial news\n",
    "Creates a function to retrive financial news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0  2023-03-24T13:00:11+00:00   \n",
      "1  2023-02-17T11:01:03+00:00   \n",
      "2  2023-02-14T14:24:02+00:00   \n",
      "3  2023-01-26T13:06:00+00:00   \n",
      "4  2023-01-18T11:00:49+00:00   \n",
      "5  2023-01-14T12:04:45+00:00   \n",
      "6  2023-01-01T23:08:43+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Apple (NASDAQ:AAPL) Seems To Use Debt Quite Se...   \n",
      "1        Is Apple (NASDAQ:AAPL) Using Too Much Debt?   \n",
      "2  This Semiconductor Stock Has Too Much Dependen...   \n",
      "3  If Cash Is King, These Nasdaq Stocks Reign Sup...   \n",
      "4  Apple (NASDAQ:AAPL) Could Easily Take On More ...   \n",
      "5            7 Stocks to Buy and Hold For a Lifetime   \n",
      "6  Lessons Learned From Visa and Mastercard in a ...   \n",
      "\n",
      "                                             content  \\\n",
      "0  Howard Marks put it nicely when he said that, ...   \n",
      "1  David Iben put it well when he said, 'Volatili...   \n",
      "2  In today's video, Jose Najarro, Nick Rossolill...   \n",
      "3  Because of that, companies that generate lots ...   \n",
      "4  Howard Marks put it nicely when he said that, ...   \n",
      "5  I always trust the idea of buying and holding ...   \n",
      "6  How Visa and Mastercard fared in a year domina...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "1  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "2  https://finance.yahoo.com/m/0343376c-2f5b-3a27...   \n",
      "3  https://finance.yahoo.com/m/69541834-9082-3301...   \n",
      "4  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "5  https://finance.yahoo.com/news/7-stocks-buy-ho...   \n",
      "6  https://finance.yahoo.com/m/4b9f894a-9854-3caf...   \n",
      "\n",
      "                                             symbols  \\\n",
      "0    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "1    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "2  [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...   \n",
      "3  [AAPL.MX, AAPL.US, AAPL34.SA, ABEA.F, ABEA.XET...   \n",
      "4    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "5  [AAPL.US, CHV.F, CHV.XETRA, COST.MX, COST.US, ...   \n",
      "6  [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...   \n",
      "\n",
      "                                                tags  \\\n",
      "0  [APPLE INC, BALANCE SHEET, DEBT LEVELS, DEBT T...   \n",
      "1  [APPLE INC, BALANCE SHEET, DEBT LEVELS, DEBT T...   \n",
      "2  [APPLE, BALANCE SHEET, JOSE NAJARRO, NICK ROSS...   \n",
      "3  [BALANCE SHEET, BALANCE SHEETS, CASH FLOW, CAS...   \n",
      "4  [APPLE INC, BALANCE SHEET, DEBT LEVELS, EBIT, ...   \n",
      "5  [BALANCE SHEET, CAPITAL GAINS, CASH FLOWS, CHE...   \n",
      "6  [BALANCE SHEET, CHRIS HILL, JASON MOSER, MASTE...   \n",
      "\n",
      "                                           sentiment  \n",
      "0  {'polarity': 0.993, 'neg': 0.109, 'neu': 0.744...  \n",
      "1  {'polarity': 0.997, 'neg': 0.117, 'neu': 0.711...  \n",
      "2  {'polarity': -0.44, 'neg': 0.108, 'neu': 0.851...  \n",
      "3  {'polarity': 0.511, 'neg': 0, 'neu': 0.936, 'p...  \n",
      "4  {'polarity': 0.983, 'neg': 0.115, 'neu': 0.745...  \n",
      "5  {'polarity': 1, 'neg': 0.017, 'neu': 0.837, 'p...  \n",
      "6  {'polarity': 0.7, 'neg': 0, 'neu': 0.876, 'pos...  \n"
     ]
    }
   ],
   "source": [
    "def fetch_news_data(stock, tag ,begin_date, end_date, offset =0 , api_token =API_Eodhd):\n",
    "    \"\"\"\n",
    "    Fetch news data for a given stock and return it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock (str): The stock symbol (e.g., \"AAPL.US\").\n",
    "        begin_date (str): The start date in \"YYYY-MM-DD\" format.\n",
    "        end_date (str): The end date in \"YYYY-MM-DD\" format.\n",
    "        tag (str): The tag to filter news (e.g., \"balance sheet\"). List of tags : 'balance sheet', 'capital employed', 'class action', 'company announcement', 'consensus eps estimate', 'consensus estimate', 'credit rating', 'discounted cash flow', 'dividend payments', 'earnings estimate', 'earnings growth', 'earnings per share', 'earnings release', 'earnings report', 'earnings results', 'earnings surprise', 'estimate revisions', 'european regulatory news', 'financial results', 'fourth quarter', 'free cash flow', 'future cash flows', 'growth rate', 'initial public offering', 'insider ownership', 'insider transactions', 'institutional investors', 'institutional ownership', 'intrinsic value', 'market research reports', 'net income', 'operating income', 'present value', 'press releases', 'price target', 'quarterly earnings', 'quarterly results', 'ratings', 'research analysis and reports', 'return on equity', 'revenue estimates', 'revenue growth', 'roce', 'roe', 'share price', 'shareholder rights', 'shareholder', 'shares outstanding', 'split', 'strong buy', 'total revenue', 'zacks investment research', 'zacks rank'\n",
    "        offset (int): The offset for pagination.\n",
    "        api_token (str): Your API token for authentication.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The news data as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/news?s={stock}&t={tag}&offset={offset}&limit=10&api_token={api_token}&from={begin_date}&to={end_date}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Convert JSON response to Pandas DataFrame\n",
    "    news_df = pd.DataFrame(response)\n",
    "    \n",
    "    return news_df\n",
    "\n",
    "# Example usage\n",
    "stock = \"AAPL.US\"\n",
    "begin_date = \"2023-01-01\"\n",
    "end_date = \"2023-10-01\"\n",
    "tag = \"balance sheet\"\n",
    "offset = 0\n",
    "\n",
    "news_df = fetch_news_data(stock, tag ,begin_date, end_date)\n",
    "print(news_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting fundamental data\n",
    "Creating a function retrive fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  General.Code  General.Type General.Name General.Exchange  \\\n",
      "0         AAPL  Common Stock    Apple Inc           NASDAQ   \n",
      "\n",
      "  General.CurrencyCode General.CurrencyName General.CurrencySymbol  \\\n",
      "0                  USD            US Dollar                      $   \n",
      "\n",
      "  General.CountryName General.CountryISO General.OpenFigi  ...  \\\n",
      "0                 USA                 US     BBG000B9XRY4  ...   \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.otherItems  \\\n",
      "0                                               None         \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.incomeTaxExpense  \\\n",
      "0                                        58800000.00               \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.totalRevenue  \\\n",
      "0                                      1918300000.00           \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.totalOperatingExpenses  \\\n",
      "0                                       695000000.00                     \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.costOfRevenue  \\\n",
      "0                                      1076000000.00            \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.totalOtherIncomeExpenseNet  \\\n",
      "0                                       -27300000.00                         \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.discontinuedOperations  \\\n",
      "0                                               None                     \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.netIncomeFromContinuingOps  \\\n",
      "0                                               None                         \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.netIncomeApplicableToCommonShares  \\\n",
      "0                                               None                                \n",
      "\n",
      "  Financials.Income_Statement.yearly.1985-09-30.preferredStockAndOtherAdjustments  \n",
      "0                                               None                               \n",
      "\n",
      "[1 rows x 28020 columns]\n"
     ]
    }
   ],
   "source": [
    "def fetch_fundamentals(stock, api_token=API_Eodhd):\n",
    "    \"\"\"\n",
    "    Fetch fundamental data for a given stock and return it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock (str): The stock symbol (e.g., \"AAPL.US\").\n",
    "        api_token (str): Your API token for authentication.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The fundamental data as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/fundamentals/{stock}?api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Flatten the JSON response and convert it to a Pandas DataFrame\n",
    "    fundamentals_df = pd.json_normalize(response)\n",
    "    \n",
    "    return fundamentals_df\n",
    "\n",
    "# Example usage\n",
    "api_token = API_Eodhd  # Replace with your actual API token\n",
    "stock = \"AAPL.US\"\n",
    "\n",
    "fundamentals_df = fetch_fundamentals(stock, api_token)\n",
    "print(fundamentals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting macro economic data\n",
    "Creating a function retrive macroeconomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CountryCode    CountryName                              Indicator  \\\n",
      "0          USA  United States  Inflation, consumer prices (annual %)   \n",
      "1          USA  United States  Inflation, consumer prices (annual %)   \n",
      "2          USA  United States  Inflation, consumer prices (annual %)   \n",
      "3          USA  United States  Inflation, consumer prices (annual %)   \n",
      "4          USA  United States  Inflation, consumer prices (annual %)   \n",
      "..         ...            ...                                    ...   \n",
      "59         USA  United States  Inflation, consumer prices (annual %)   \n",
      "60         USA  United States  Inflation, consumer prices (annual %)   \n",
      "61         USA  United States  Inflation, consumer prices (annual %)   \n",
      "62         USA  United States  Inflation, consumer prices (annual %)   \n",
      "63         USA  United States  Inflation, consumer prices (annual %)   \n",
      "\n",
      "          Date  Period   Value  \n",
      "0   2023-12-31  Annual  4.1163  \n",
      "1   2022-12-31  Annual  8.0028  \n",
      "2   2021-12-31  Annual  4.6979  \n",
      "3   2020-12-31  Annual  1.2336  \n",
      "4   2019-12-31  Annual  1.8122  \n",
      "..         ...     ...     ...  \n",
      "59  1964-12-31  Annual  1.2789  \n",
      "60  1963-12-31  Annual  1.2397  \n",
      "61  1962-12-31  Annual  1.1988  \n",
      "62  1961-12-31  Annual  1.0707  \n",
      "63  1960-12-31  Annual  1.4580  \n",
      "\n",
      "[64 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def fetch_macro_indicator(country, indicator, api_token=API_Eodhd):\n",
    "    \"\"\"\n",
    "    Fetch macroeconomic indicator data for a given country and return it as a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        country (str): The country code (e.g., \"USA\").\n",
    "        indicator (str): The macroeconomic indicator (e.g., \"inflation_consumer_prices_annual\"). List of indicators: https://eodhd.com/financial-apis/macroeconomics-data-and-macro-indicators-api\n",
    "        api_token (str): Your API token for authentication.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The macroeconomic indicator data as a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/macro-indicator/{country}?indicator={indicator}&api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    # Convert JSON response to Pandas DataFrame\n",
    "    macro_df = pd.DataFrame(response)\n",
    "    \n",
    "    return macro_df\n",
    "\n",
    "# Example usage\n",
    "country = \"USA\"\n",
    "indicator = \"inflation_consumer_prices_annual\"\n",
    "macro_df = fetch_macro_indicator(country, indicator)\n",
    "print(macro_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting intraday stock data\n",
    "Creating a function retrive stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp  gmtoffset            datetime        open        high  \\\n",
      "0  1733236200          0 2024-12-03 14:30:00  239.192398  239.940002   \n",
      "1  1733236500          0 2024-12-03 14:35:00  239.550003  239.668106   \n",
      "2  1733236800          0 2024-12-03 14:40:00  239.389999  239.710006   \n",
      "3  1733237100          0 2024-12-03 14:45:00  239.610000  240.639801   \n",
      "4  1733237400          0 2024-12-03 14:50:00  240.619995  240.729995   \n",
      "\n",
      "          low       close     volume  \n",
      "0  238.900299  239.565002  2496034.0  \n",
      "1  238.990005  239.369995   532222.0  \n",
      "2  239.110000  239.615005   414728.0  \n",
      "3  239.589996  240.589996   868554.0  \n",
      "4  240.270004  240.695007   571623.0  \n"
     ]
    }
   ],
   "source": [
    "def fetch_intraday_data(stock, api_token= API_Eodhd):\n",
    "    \"\"\"\n",
    "    Fetch intraday data for a given stock from the EODHD API and convert it to a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock (str): The stock symbol (e.g., \"AAPL.US\").\n",
    "        api_token (str): Your API token for authentication.\n",
    "        interval (str): The interval for intraday data (e.g., \"1m\", \"5m\", \"15m\", \"1h\"). Default is \"1m\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the intraday data.\n",
    "    \"\"\"\n",
    "    url = f'https://eodhd.com/api/intraday/{stock}?api_token={api_token}&fmt=json'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert JSON to Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the 'datetime' column is in datetime format\n",
    "    if 'datetime' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "stock = \"AAPL.US\"\n",
    "\n",
    "intraday_data = fetch_intraday_data(stock)\n",
    "print(intraday_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running correlation between all the stocks in the exchange\n",
    "Creates a list of all the correlations betweens stocks and sorts them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m tickers = fetch_exchange_symbols(\u001b[33m\"\u001b[39m\u001b[33mAS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m tickers_subset = tickers\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m sorted_correlations_df = \u001b[43mcalculate_and_sort_correlations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mETF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(sorted_correlations_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcalculate_and_sort_correlations\u001b[39m\u001b[34m(tickers_df, exchange, instrument_type, api_token, start_date, end_date, period)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Combine ticker with exchange code\u001b[39;00m\n\u001b[32m     24\u001b[39m     full_ticker = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexchange\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     stock_df = \u001b[43mFetch_historical_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_ticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madjusted_close\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     stock_data[ticker] = stock_df.set_index(\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33madjusted_close\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mFetch_historical_price\u001b[39m\u001b[34m(stock1, begin_date, end_date, period, api_token, columns)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mFetch stock data from the EODHD API and return it as a filtered Pandas DataFrame.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03m    pd.DataFrame: The filtered stock data as a Pandas DataFrame.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://eodhd.com/api/eod/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?from=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbegin_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&to=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&period=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&api_token=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&fmt=json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m.json()\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Convert JSON to Pandas DataFrame\u001b[39;00m\n\u001b[32m     20\u001b[39m pandas_df = pd.DataFrame(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def calculate_and_sort_correlations(tickers_df, exchange, instrument_type=\"Common Stock\", api_token=API_Eodhd, start_date=\"2025-01-01\", end_date=\"2025-03-30\", period=\"d\"):\n",
    "    \"\"\"\n",
    "    Calculate the correlation between all stocks in an exchange and sort them from least to highest.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (pd.DataFrame): DataFrame containing stock tickers.\n",
    "        exchange (str): Exchange code to append to tickers (e.g., \"US\").\n",
    "        instrument_type (str): Type of the instrument to filter (e.g., \"Common Stock\").\n",
    "        api_token (str): API token for authentication.\n",
    "        start_date (str): Start date for historical data.\n",
    "        end_date (str): End date for historical data.\n",
    "        period (str): Period for historical data (e.g., \"d\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing stock pairs and their correlation, sorted by correlation value.\n",
    "    \"\"\"\n",
    "    # Filter tickers to include only the specified instrument type\n",
    "    filtered_tickers_df = tickers_df[tickers_df[\"Type\"] == instrument_type]\n",
    "\n",
    "    stock_data = {}\n",
    "    for ticker in filtered_tickers_df['Code']:\n",
    "        try:\n",
    "            # Combine ticker with exchange code\n",
    "            full_ticker = f\"{ticker}.{exchange}\"\n",
    "            stock_df = Fetch_historical_price(full_ticker, start_date, end_date, period, api_token, columns=[\"adjusted_close\"])\n",
    "            stock_data[ticker] = stock_df.set_index(\"date\")[\"adjusted_close\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Combine all stock data into a single DataFrame\n",
    "    combined_df = pd.DataFrame(stock_data)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = combined_df.corr()\n",
    "\n",
    "    # Create a list of all pairs and their correlations\n",
    "    correlations = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            stock1 = correlation_matrix.columns[i]\n",
    "            stock2 = correlation_matrix.columns[j]\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            correlations.append({\"Instrument 1\": stock1, \"Instrument 2\": stock2, \"Correlation\": correlation})\n",
    "\n",
    "    # Convert the list of correlations to a DataFrame\n",
    "    correlations_df = pd.DataFrame(correlations)\n",
    "\n",
    "    # Sort the DataFrame by correlation value\n",
    "    correlations_df = correlations_df.sort_values(by=\"Correlation\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return correlations_df\n",
    "\n",
    "# Example usage\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "tickers_subset = tickers\n",
    "sorted_correlations_df = calculate_and_sort_correlations(tickers_subset, \"AS\", instrument_type=\"ETF\")\n",
    "print(sorted_correlations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting output to excel\n",
    "Creates an excel export in the python folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory and file path\n",
    "output_dir = r\"E:\\Business NL\\Python\\Excel output\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "output_file = os.path.join(output_dir, \"sorted_correlations.xlsx\")\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "sorted_correlations_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sorted correlations exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing sentement with finbert model\n",
    "Creates a function to use finbert model to analyze sentement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0  2023-03-24T13:00:11+00:00   \n",
      "1  2023-02-17T11:01:03+00:00   \n",
      "2  2023-02-14T14:24:02+00:00   \n",
      "3  2023-01-26T13:06:00+00:00   \n",
      "4  2023-01-18T11:00:49+00:00   \n",
      "5  2023-01-14T12:04:45+00:00   \n",
      "6  2023-01-01T23:08:43+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Apple (NASDAQ:AAPL) Seems To Use Debt Quite Se...   \n",
      "1        Is Apple (NASDAQ:AAPL) Using Too Much Debt?   \n",
      "2  This Semiconductor Stock Has Too Much Dependen...   \n",
      "3  If Cash Is King, These Nasdaq Stocks Reign Sup...   \n",
      "4  Apple (NASDAQ:AAPL) Could Easily Take On More ...   \n",
      "5            7 Stocks to Buy and Hold For a Lifetime   \n",
      "6  Lessons Learned From Visa and Mastercard in a ...   \n",
      "\n",
      "                                             content  \\\n",
      "0  Howard Marks put it nicely when he said that, ...   \n",
      "1  David Iben put it well when he said, 'Volatili...   \n",
      "2  In today's video, Jose Najarro, Nick Rossolill...   \n",
      "3  Because of that, companies that generate lots ...   \n",
      "4  Howard Marks put it nicely when he said that, ...   \n",
      "5  I always trust the idea of buying and holding ...   \n",
      "6  How Visa and Mastercard fared in a year domina...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "1  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "2  https://finance.yahoo.com/m/0343376c-2f5b-3a27...   \n",
      "3  https://finance.yahoo.com/m/69541834-9082-3301...   \n",
      "4  https://finance.yahoo.com/news/apple-nasdaq-aa...   \n",
      "5  https://finance.yahoo.com/news/7-stocks-buy-ho...   \n",
      "6  https://finance.yahoo.com/m/4b9f894a-9854-3caf...   \n",
      "\n",
      "                                             symbols  \\\n",
      "0    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "1    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "2  [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...   \n",
      "3  [AAPL.MX, AAPL.US, AAPL34.SA, ABEA.F, ABEA.XET...   \n",
      "4    [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
      "5  [AAPL.US, CHV.F, CHV.XETRA, COST.MX, COST.US, ...   \n",
      "6  [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...   \n",
      "\n",
      "                                                tags  \\\n",
      "0  [APPLE INC, BALANCE SHEET, DEBT LEVELS, DEBT T...   \n",
      "1  [APPLE INC, BALANCE SHEET, DEBT LEVELS, DEBT T...   \n",
      "2  [APPLE, BALANCE SHEET, JOSE NAJARRO, NICK ROSS...   \n",
      "3  [BALANCE SHEET, BALANCE SHEETS, CASH FLOW, CAS...   \n",
      "4  [APPLE INC, BALANCE SHEET, DEBT LEVELS, EBIT, ...   \n",
      "5  [BALANCE SHEET, CAPITAL GAINS, CASH FLOWS, CHE...   \n",
      "6  [BALANCE SHEET, CHRIS HILL, JASON MOSER, MASTE...   \n",
      "\n",
      "                                           sentiment Sentiment  \n",
      "0  {'polarity': 0.993, 'neg': 0.109, 'neu': 0.744...   Neutral  \n",
      "1  {'polarity': 0.997, 'neg': 0.117, 'neu': 0.711...   Neutral  \n",
      "2  {'polarity': -0.44, 'neg': 0.108, 'neu': 0.851...  Negative  \n",
      "3  {'polarity': 0.511, 'neg': 0, 'neu': 0.936, 'p...  Positive  \n",
      "4  {'polarity': 0.983, 'neg': 0.115, 'neu': 0.745...   Neutral  \n",
      "5  {'polarity': 1, 'neg': 0.017, 'neu': 0.837, 'p...  Positive  \n",
      "6  {'polarity': 0.7, 'neg': 0, 'neu': 0.876, 'pos...  Positive  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_sentiment_with_finbert(news_df):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of news articles using FinBERT.\n",
    "\n",
    "    Parameters:\n",
    "        news_df (pd.DataFrame): DataFrame containing news articles.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional 'Sentiment' column.\n",
    "    \"\"\"\n",
    "    if 'content' not in news_df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'content' column for sentiment analysis.\")\n",
    "    \n",
    "    # Load the FinBERT sentiment analysis pipeline with explicit truncation\n",
    "    finbert = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"yiyanghkust/finbert-tone\",\n",
    "        tokenizer=\"yiyanghkust/finbert-tone\",\n",
    "        device=0,  # Use CPU (-1) or GPU (0 or higher)\n",
    "        truncation=True,\n",
    "        max_length=512  # Explicitly set the maximum length\n",
    "    )\n",
    "    \n",
    "    # Apply sentiment analysis to the 'content' column\n",
    "    def analyze_text(text):\n",
    "        try:\n",
    "            return finbert(text[:512])[0]['label']  # Truncate text to 512 characters\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    news_df['Sentiment'] = news_df['content'].apply(analyze_text)\n",
    "    \n",
    "    return news_df\n",
    "\n",
    "# Example usage\n",
    "api_token = API_Eodhd  # Replace with your actual API token\n",
    "stock = \"AAPL.US\"\n",
    "begin_date = \"2023-01-01\"\n",
    "end_date = \"2025-03-01\"\n",
    "tag = \"balance sheet\"\n",
    "\n",
    "# Fetch news data\n",
    "news_df = fetch_news_data(stock, tag, begin_date, end_date, api_token=api_token)\n",
    "\n",
    "# Perform sentiment analysis with FinBERT\n",
    "news_with_sentiment = analyze_sentiment_with_finbert(news_df)\n",
    "\n",
    "print(news_with_sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
