{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, such as requests, for making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library for making API calls\n",
    "# Install necessary libraries\n",
    "'''%pip install requests\n",
    "%pip install pandas\n",
    "%pip install datetime\n",
    "%pip install cudf\n",
    "%pip install cupy\n",
    "%pip install openpyxl\n",
    "%pip install textblob\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install import-ipynb'''\n",
    "\n",
    "# Import libraries\n",
    "import import_ipynb\n",
    "from Input_Tools import *\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define API Key\n",
    "Define the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Eodhd = \"66c0aeb1357b15.87356825\"\n",
    "\n",
    "# Important link: https://eodhd.com/financial-academy/financial-faq/fundamentals-glossary-common-stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running correlation between all the stocks in the exchange\n",
    "Creates a list of all the correlations betweens stocks and sorts them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_sort_correlations(tickers_df, exchange, instrument_type=\"Common Stock\", api_token=API_Eodhd, start_date=\"2025-01-01\", end_date=\"2025-03-30\", period=\"d\"):\n",
    "    \"\"\"\n",
    "    Calculate the correlation between all stocks in an exchange and sort them from least to highest.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (pd.DataFrame): DataFrame containing stock tickers.\n",
    "        exchange (str): Exchange code to append to tickers (e.g., \"US\").\n",
    "        instrument_type (str): Type of the instrument to filter (e.g., \"Common Stock\").\n",
    "        api_token (str): API token for authentication.\n",
    "        start_date (str): Start date for historical data.\n",
    "        end_date (str): End date for historical data.\n",
    "        period (str): Period for historical data (e.g., \"d\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing stock pairs and their correlation, sorted by correlation value.\n",
    "    \"\"\"\n",
    "    # Filter tickers to include only the specified instrument type\n",
    "    filtered_tickers_df = tickers_df[tickers_df[\"Type\"] == instrument_type]\n",
    "\n",
    "    stock_data = {}\n",
    "    for ticker in filtered_tickers_df['Code']:\n",
    "        try:\n",
    "            # Combine ticker with exchange code\n",
    "            full_ticker = f\"{ticker}.{exchange}\"\n",
    "            stock_df = Fetch_historical_price(full_ticker, start_date, end_date, period, api_token, columns=[\"adjusted_close\"])\n",
    "            stock_data[ticker] = stock_df.set_index(\"date\")[\"adjusted_close\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Combine all stock data into a single DataFrame\n",
    "    combined_df = pd.DataFrame(stock_data)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = combined_df.corr()\n",
    "\n",
    "    # Create a list of all pairs and their correlations\n",
    "    correlations = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            stock1 = correlation_matrix.columns[i]\n",
    "            stock2 = correlation_matrix.columns[j]\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            correlations.append({\"Instrument 1\": stock1, \"Instrument 2\": stock2, \"Correlation\": correlation})\n",
    "\n",
    "    # Convert the list of correlations to a DataFrame\n",
    "    correlations_df = pd.DataFrame(correlations)\n",
    "\n",
    "    # Sort the DataFrame by correlation value\n",
    "    correlations_df = correlations_df.sort_values(by=\"Correlation\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return correlations_df\n",
    "\n",
    "# Example usage\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "tickers_subset = tickers\n",
    "sorted_correlations_df = calculate_and_sort_correlations(tickers_subset, \"AS\", instrument_type=\"ETF\")\n",
    "print(sorted_correlations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Instrument 1 Instrument 2  Correlation\n",
      "0             ASUI         IGAE    -0.955742\n",
      "1             ASUI         ERNE    -0.955058\n",
      "2             IGAE         VETH    -0.953517\n",
      "3             AARB         ERNE    -0.952854\n",
      "4             ETHW         IGAE    -0.951588\n",
      "...            ...          ...          ...\n",
      "46051         SPYL         VUSA     0.999924\n",
      "46052         CSPX         IUSA     0.999965\n",
      "46053         IWDA         SWRD     0.999969\n",
      "46054         CSPX         VUSA     0.999977\n",
      "46055         IUSA         VUSA     0.999977\n",
      "\n",
      "[46056 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#optimized version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fetch_stock_data(ticker, exchange, start_date, end_date, period, api_token):\n",
    "    \"\"\"Helper function to fetch stock data for a single ticker.\"\"\"\n",
    "    try:\n",
    "        full_ticker = f\"{ticker}.{exchange}\"\n",
    "        stock_df = Fetch_historical_price(full_ticker, start_date, end_date, period, api_token, columns=[\"adjusted_close\"])\n",
    "        return ticker, stock_df.set_index(\"date\")[\"adjusted_close\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return ticker, None\n",
    "\n",
    "def calculate_and_sort_correlations(tickers_df, exchange, instrument_type=\"Common Stock\", api_token=API_Eodhd, start_date=\"2025-01-01\", end_date=\"2025-03-30\", period=\"d\"):\n",
    "    \"\"\"\n",
    "    Calculate the correlation between all stocks in an exchange and sort them from least to highest.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (pd.DataFrame): DataFrame containing stock tickers.\n",
    "        exchange (str): Exchange code to append to tickers (e.g., \"US\").\n",
    "        instrument_type (str): Type of the instrument to filter (e.g., \"Common Stock\").\n",
    "        api_token (str): API token for authentication.\n",
    "        start_date (str): Start date for historical data.\n",
    "        end_date (str): End date for historical data.\n",
    "        period (str): Period for historical data (e.g., \"d\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing stock pairs and their correlation, sorted by correlation value.\n",
    "    \"\"\"\n",
    "    # Filter tickers to include only the specified instrument type\n",
    "    filtered_tickers_df = tickers_df[tickers_df[\"Type\"] == instrument_type]\n",
    "\n",
    "    # Fetch stock data in parallel\n",
    "    stock_data = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(fetch_stock_data, ticker, exchange, start_date, end_date, period, api_token)\n",
    "            for ticker in filtered_tickers_df['Code']\n",
    "        ]\n",
    "        for future in futures:\n",
    "            ticker, data = future.result()\n",
    "            if data is not None:\n",
    "                stock_data[ticker] = data\n",
    "\n",
    "    # Combine all stock data into a single DataFrame\n",
    "    combined_df = pd.DataFrame(stock_data).dropna(axis=1, how=\"any\")  # Drop columns with NaN values\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = combined_df.corr()\n",
    "\n",
    "    # Flatten the correlation matrix into a DataFrame\n",
    "    correlations_df = (\n",
    "        correlation_matrix.stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\": \"Instrument 1\", \"level_1\": \"Instrument 2\", 0: \"Correlation\"})\n",
    "    )\n",
    "\n",
    "    # Remove self-correlations and duplicates\n",
    "    correlations_df = correlations_df[correlations_df[\"Instrument 1\"] < correlations_df[\"Instrument 2\"]]\n",
    "\n",
    "    # Sort the DataFrame by correlation value\n",
    "    correlations_df = correlations_df.sort_values(by=\"Correlation\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return correlations_df\n",
    "\n",
    "# Example usage\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "tickers_subset = tickers\n",
    "sorted_correlations_df = calculate_and_sort_correlations(tickers_subset, \"AS\", instrument_type=\"ETF\")\n",
    "print(sorted_correlations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting output to excel\n",
    "Creates an excel export in the python folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory and file path\n",
    "output_dir = r\"E:\\Business NL\\Python\\Excel output\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "output_file = os.path.join(output_dir, \"sorted_correlations.xlsx\")\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "sorted_correlations_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sorted correlations exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing sentement with finbert model\n",
    "Creates a function to use finbert model to analyze sentement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment_with_finbert(news_df):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of news articles using FinBERT.\n",
    "\n",
    "    Parameters:\n",
    "        news_df (pd.DataFrame): DataFrame containing news articles.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional 'Sentiment' column.\n",
    "    \"\"\"\n",
    "    if 'content' not in news_df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'content' column for sentiment analysis.\")\n",
    "    \n",
    "    # Load the FinBERT sentiment analysis pipeline with explicit truncation\n",
    "    finbert = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"yiyanghkust/finbert-tone\",\n",
    "        tokenizer=\"yiyanghkust/finbert-tone\",\n",
    "        device=0,  # Use CPU (-1) or GPU (0 or higher)\n",
    "        truncation=True,\n",
    "        max_length=512  # Explicitly set the maximum length\n",
    "    )\n",
    "    \n",
    "    # Apply sentiment analysis to the 'content' column\n",
    "    def analyze_text(text):\n",
    "        try:\n",
    "            return finbert(text[:512])[0]['label']  # Truncate text to 512 characters\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    news_df['Sentiment'] = news_df['content'].apply(analyze_text)\n",
    "    \n",
    "    return news_df\n",
    "\n",
    "# Example usage\n",
    "api_token = API_Eodhd  # Replace with your actual API token\n",
    "stock = \"AAPL.US\"\n",
    "begin_date = \"2023-01-01\"\n",
    "end_date = \"2025-03-01\"\n",
    "tag = \"balance sheet\"\n",
    "\n",
    "# Fetch news data\n",
    "news_df = fetch_news_data(stock, tag, begin_date, end_date, api_token=api_token)\n",
    "\n",
    "# Perform sentiment analysis with FinBERT\n",
    "news_with_sentiment = analyze_sentiment_with_finbert(news_df)\n",
    "\n",
    "print(news_with_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading strategy: Use last 12 months dividends to price a stock/option\n",
    "A trading strategy where I use last 12 months dividends and price the stock/option at 6% dividend yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fetch_dividend_share(tickers_df, exchange):\n",
    "    \"\"\"\n",
    "    Fetch dividend share for all stocks in the tickers_df and combine them into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (list or pd.Series): List of stock tickers (e.g., [\"INGA\", \"ASML\"]).\n",
    "        exchange (str): Exchange code (e.g., \"AS\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with two columns: 'Ticker' and 'DividendYield(%)'.\n",
    "    \"\"\"\n",
    "    combined_data = []  # Initialize an empty list to store data\n",
    "    full_tickers = [f\"{ticker}.{exchange}\" for ticker in tickers_df]\n",
    "\n",
    "    for stock in full_tickers:\n",
    "        try:\n",
    "            # Fetch the dividend share for the current stock\n",
    "            url = f'https://eodhd.com/api/fundamentals/{stock}?api_token={API_Eodhd}&filter=Highlights::DividendShare&fmt=json'\n",
    "            dividend_share = requests.get(url).json()\n",
    "\n",
    "                   \n",
    "            # Append the stock and dividend yield to the list\n",
    "            combined_data.append({\"Ticker\": stock, \"Dividendshare\": dividend_share})\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {stock}: {e}\")\n",
    "\n",
    "    # Convert the combined data into a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Drop rows with missing dividend yield values\n",
    "    combined_df = combined_df.dropna(subset=[\"Dividendshare\"])\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ticker  Dividendshare  TheoreticalStockPrice  StockPrice  Potential\n",
      "0  INGA.AS           1.06                  17.67       15.17      14.15\n",
      "1  ASML.AS           6.40                 106.67      677.30    -534.97\n",
      "2   ABN.AS           1.35                  22.50       15.19      32.49\n"
     ]
    }
   ],
   "source": [
    "# Creating a theoretical value of the stock\n",
    "tickers = [\"INGA\", \"ASML\", \"ABN\"]\n",
    "Exchange = \"AS\"\n",
    "Dividend_share = Fetch_dividend_share(tickers, Exchange).dropna(subset=[\"Dividendshare\"])\n",
    "\n",
    "Theoretical_DY = 0.06\n",
    "\n",
    "# Ensure 'Dividendshare' is numeric, replace non-numeric values with 0\n",
    "Dividend_share[\"Dividendshare\"] = pd.to_numeric(Dividend_share[\"Dividendshare\"], errors='coerce').fillna(0)\n",
    "\n",
    "# Calculate the theoretical stock price, handling division by zero\n",
    "Dividend_share[\"TheoreticalStockPrice\"] = np.where(\n",
    "    Theoretical_DY != 0,  # Check if the denominator is not zero\n",
    "    Dividend_share[\"Dividendshare\"] / Theoretical_DY,  # Perform the division\n",
    "    0  # Return 0 if the denominator is zero\n",
    ")\n",
    "\n",
    "# Initialize a dictionary to store the 'High' prices for each ticker\n",
    "high_prices = {}\n",
    "\n",
    "# Loop through each ticker to fetch the latest price data and extract the 'High' value\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Fetch the latest price data\n",
    "        latest_price = fetch_intraday_data(f\"{ticker}.{Exchange}\").iloc[0]\n",
    "        \n",
    "        # Extract the 'High' value and store it in the dictionary\n",
    "        high_prices[f\"{ticker}.{Exchange}\"] = latest_price[\"high\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        high_prices[f\"{ticker}.{Exchange}\"] = None\n",
    "\n",
    "# Add the 'High' values to the Dividend_share DataFrame\n",
    "Dividend_share[\"StockPrice\"] = Dividend_share[\"Ticker\"].map(high_prices)\n",
    "\n",
    "# Calculating upside/downside potential, handling division by zero\n",
    "Dividend_share[\"Potential\"] = np.where(\n",
    "    Dividend_share[\"TheoreticalStockPrice\"] != 0,  # Check if the denominator is not zero\n",
    "    (Dividend_share[\"TheoreticalStockPrice\"] - Dividend_share[\"StockPrice\"]) * 100 / Dividend_share[\"TheoreticalStockPrice\"],  # Perform the calculation\n",
    "    0  # Return 0 if the denominator is zero\n",
    ")\n",
    "\n",
    "# Round the specified columns to 2 decimal places\n",
    "Dividend_share[\"TheoreticalStockPrice\"] = Dividend_share[\"TheoreticalStockPrice\"].round(2)\n",
    "Dividend_share[\"StockPrice\"] = Dividend_share[\"StockPrice\"].round(2)\n",
    "Dividend_share[\"Potential\"] = Dividend_share[\"Potential\"].round(2)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(Dividend_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AALB', 'ABN', 'ACOMO', 'AD', 'ADYEN', 'AGN', 'AJAX', 'AKZA', 'ALFEN', 'ALLFG', 'ALX', 'AMG', 'APAM', 'ARCAD', 'ASM', 'ASML', 'ASRNL', 'AVTX', 'AXS', 'AZRN', 'BAI', 'BAMNB', 'BESI', 'BEVER', 'BFIT', 'BNJ', 'BRNL', 'BSGR', 'CCEP', 'CMCOM', 'CRBN', 'CTAC', 'CTPNV', 'CVC', 'DGB', 'DSFIR', 'EAS2P', 'EBUS', 'ECMPA', 'ECT', 'ENVI', 'EXO', 'FAST', 'FER', 'FERGR', 'FFARM', 'FLOW', 'FUR', 'GLPG', 'GOLD', 'HAL', 'HAVAS', 'HEIA', 'HEIJM', 'HEIO', 'HOLCO', 'HYDRA', 'IEX', 'IMCD', 'INGA', 'INPST', 'JDEP', 'KENDR', 'KPN', 'LIGHT', 'LVIDE', 'MT', 'NEDAP', 'NEDSE', 'NN', 'NRP', 'NSE', 'NSI', 'NXFIL', 'OCI', 'PBH', 'PHARM', 'PHIA', 'PNL', 'PORF', 'PREVA', 'PRX', 'PSH', 'RAND', 'REINA', 'REN', 'ROBA', 'SBMO', 'SHELL', 'SIFG', 'SLIGR', 'TFG', 'THEON', 'TKWY', 'TLT', 'TOM2', 'TWEKA', 'UMG', 'UNA', 'VALUE', 'VLK', 'VPK', 'VVY', 'WHA', 'WKL']\n"
     ]
    }
   ],
   "source": [
    "# Fetch all stocks from the exchange\n",
    "All_stocks = fetch_exchange_symbols(\"AS\")\n",
    "\n",
    "# Filter for rows where Type is \"CommonStock\"\n",
    "common_stocks = All_stocks[All_stocks[\"Type\"] == \"Common Stock\"]\n",
    "\n",
    "# Extract the 'Code' column as a one-dimensional array\n",
    "tickers_all = common_stocks[\"Code\"].tolist()\n",
    "\n",
    "# Print the resulting tickers\n",
    "print(tickers_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the stocks into 3 quintiles\n",
    "Separating the stocks into small cap, midcap and large cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily trading market volume = close price * volume\n",
    "# Take an average of the last 30 days\n",
    "# separate them into three quintiles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
