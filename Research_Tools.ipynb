{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, such as requests, for making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for INGA.AS: name 'Fetch_dividend_yield' is not defined\n",
      "Error fetching data for ASML.AS: name 'Fetch_dividend_yield' is not defined\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['DividendYield(%)']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_27636\\3170503732.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m %pip install import-ipynb'''\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m import_ipynb\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m Input_Tools \u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m requests\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m pandas \u001b[38;5;28;01mas\u001b[39;00m pd\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m datetime \u001b[38;5;28;01mas\u001b[39;00m dt\n",
      "\u001b[32m<frozen importlib._bootstrap>\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[32m<frozen importlib._bootstrap>\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[32m<frozen importlib._bootstrap>\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\import_ipynb.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, mod)\u001b[39m\n\u001b[32m     62\u001b[39m                     )\n\u001b[32m     63\u001b[39m                     \u001b[38;5;66;03m# run the code in themodule\u001b[39;00m\n\u001b[32m     64\u001b[39m                     exec(code, mod.__dict__)\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m             self.shell.user_ns = save_user_ns\n",
      "\u001b[32m<string>\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[33m'Could not get source, probably due dynamically evaluated source code.'\u001b[39m\n",
      "\u001b[32m<string>\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(tickers_df, exchange)\u001b[39m\n",
      "\u001b[32mc:\\Users\\ravit\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['DividendYield(%)']"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for making API calls\n",
    "# Install necessary libraries\n",
    "'''%pip install requests\n",
    "%pip install pandas\n",
    "%pip install datetime\n",
    "%pip install cudf\n",
    "%pip install cupy\n",
    "%pip install openpyxl\n",
    "%pip install textblob\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install import-ipynb'''\n",
    "\n",
    "# Import libraries\n",
    "import import_ipynb\n",
    "from Input_Tools import *\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define API Key\n",
    "Define the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Eodhd = \"66c0aeb1357b15.87356825\"\n",
    "\n",
    "# Important link: https://eodhd.com/financial-academy/financial-faq/fundamentals-glossary-common-stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running correlation between all the stocks in the exchange\n",
    "Creates a list of all the correlations betweens stocks and sorts them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_sort_correlations(tickers_df, exchange, instrument_type=\"Common Stock\", api_token=API_Eodhd, start_date=\"2025-01-01\", end_date=\"2025-03-30\", period=\"d\"):\n",
    "    \"\"\"\n",
    "    Calculate the correlation between all stocks in an exchange and sort them from least to highest.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (pd.DataFrame): DataFrame containing stock tickers.\n",
    "        exchange (str): Exchange code to append to tickers (e.g., \"US\").\n",
    "        instrument_type (str): Type of the instrument to filter (e.g., \"Common Stock\").\n",
    "        api_token (str): API token for authentication.\n",
    "        start_date (str): Start date for historical data.\n",
    "        end_date (str): End date for historical data.\n",
    "        period (str): Period for historical data (e.g., \"d\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing stock pairs and their correlation, sorted by correlation value.\n",
    "    \"\"\"\n",
    "    # Filter tickers to include only the specified instrument type\n",
    "    filtered_tickers_df = tickers_df[tickers_df[\"Type\"] == instrument_type]\n",
    "\n",
    "    stock_data = {}\n",
    "    for ticker in filtered_tickers_df['Code']:\n",
    "        try:\n",
    "            # Combine ticker with exchange code\n",
    "            full_ticker = f\"{ticker}.{exchange}\"\n",
    "            stock_df = Fetch_historical_price(full_ticker, start_date, end_date, period, api_token, columns=[\"adjusted_close\"])\n",
    "            stock_data[ticker] = stock_df.set_index(\"date\")[\"adjusted_close\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Combine all stock data into a single DataFrame\n",
    "    combined_df = pd.DataFrame(stock_data)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = combined_df.corr()\n",
    "\n",
    "    # Create a list of all pairs and their correlations\n",
    "    correlations = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            stock1 = correlation_matrix.columns[i]\n",
    "            stock2 = correlation_matrix.columns[j]\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            correlations.append({\"Instrument 1\": stock1, \"Instrument 2\": stock2, \"Correlation\": correlation})\n",
    "\n",
    "    # Convert the list of correlations to a DataFrame\n",
    "    correlations_df = pd.DataFrame(correlations)\n",
    "\n",
    "    # Sort the DataFrame by correlation value\n",
    "    correlations_df = correlations_df.sort_values(by=\"Correlation\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return correlations_df\n",
    "\n",
    "# Example usage\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "tickers_subset = tickers\n",
    "sorted_correlations_df = calculate_and_sort_correlations(tickers_subset, \"AS\", instrument_type=\"ETF\")\n",
    "print(sorted_correlations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Instrument 1 Instrument 2  Correlation\n",
      "0             ASUI         IGAE    -0.955742\n",
      "1             ASUI         ERNE    -0.955058\n",
      "2             IGAE         VETH    -0.953517\n",
      "3             AARB         ERNE    -0.952854\n",
      "4             ETHW         IGAE    -0.951588\n",
      "...            ...          ...          ...\n",
      "46051         SPYL         VUSA     0.999924\n",
      "46052         CSPX         IUSA     0.999965\n",
      "46053         IWDA         SWRD     0.999969\n",
      "46054         CSPX         VUSA     0.999977\n",
      "46055         IUSA         VUSA     0.999977\n",
      "\n",
      "[46056 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#optimized version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fetch_stock_data(ticker, exchange, start_date, end_date, period, api_token):\n",
    "    \"\"\"Helper function to fetch stock data for a single ticker.\"\"\"\n",
    "    try:\n",
    "        full_ticker = f\"{ticker}.{exchange}\"\n",
    "        stock_df = Fetch_historical_price(full_ticker, start_date, end_date, period, api_token, columns=[\"adjusted_close\"])\n",
    "        return ticker, stock_df.set_index(\"date\")[\"adjusted_close\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return ticker, None\n",
    "\n",
    "def calculate_and_sort_correlations(tickers_df, exchange, instrument_type=\"Common Stock\", api_token=API_Eodhd, start_date=\"2025-01-01\", end_date=\"2025-03-30\", period=\"d\"):\n",
    "    \"\"\"\n",
    "    Calculate the correlation between all stocks in an exchange and sort them from least to highest.\n",
    "\n",
    "    Parameters:\n",
    "        tickers_df (pd.DataFrame): DataFrame containing stock tickers.\n",
    "        exchange (str): Exchange code to append to tickers (e.g., \"US\").\n",
    "        instrument_type (str): Type of the instrument to filter (e.g., \"Common Stock\").\n",
    "        api_token (str): API token for authentication.\n",
    "        start_date (str): Start date for historical data.\n",
    "        end_date (str): End date for historical data.\n",
    "        period (str): Period for historical data (e.g., \"d\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing stock pairs and their correlation, sorted by correlation value.\n",
    "    \"\"\"\n",
    "    # Filter tickers to include only the specified instrument type\n",
    "    filtered_tickers_df = tickers_df[tickers_df[\"Type\"] == instrument_type]\n",
    "\n",
    "    # Fetch stock data in parallel\n",
    "    stock_data = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(fetch_stock_data, ticker, exchange, start_date, end_date, period, api_token)\n",
    "            for ticker in filtered_tickers_df['Code']\n",
    "        ]\n",
    "        for future in futures:\n",
    "            ticker, data = future.result()\n",
    "            if data is not None:\n",
    "                stock_data[ticker] = data\n",
    "\n",
    "    # Combine all stock data into a single DataFrame\n",
    "    combined_df = pd.DataFrame(stock_data).dropna(axis=1, how=\"any\")  # Drop columns with NaN values\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = combined_df.corr()\n",
    "\n",
    "    # Flatten the correlation matrix into a DataFrame\n",
    "    correlations_df = (\n",
    "        correlation_matrix.stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\": \"Instrument 1\", \"level_1\": \"Instrument 2\", 0: \"Correlation\"})\n",
    "    )\n",
    "\n",
    "    # Remove self-correlations and duplicates\n",
    "    correlations_df = correlations_df[correlations_df[\"Instrument 1\"] < correlations_df[\"Instrument 2\"]]\n",
    "\n",
    "    # Sort the DataFrame by correlation value\n",
    "    correlations_df = correlations_df.sort_values(by=\"Correlation\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return correlations_df\n",
    "\n",
    "# Example usage\n",
    "tickers = fetch_exchange_symbols(\"AS\")\n",
    "tickers_subset = tickers\n",
    "sorted_correlations_df = calculate_and_sort_correlations(tickers_subset, \"AS\", instrument_type=\"ETF\")\n",
    "print(sorted_correlations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting output to excel\n",
    "Creates an excel export in the python folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory and file path\n",
    "output_dir = r\"E:\\Business NL\\Python\\Excel output\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "output_file = os.path.join(output_dir, \"sorted_correlations.xlsx\")\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "sorted_correlations_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sorted correlations exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing sentement with finbert model\n",
    "Creates a function to use finbert model to analyze sentement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment_with_finbert(news_df):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of news articles using FinBERT.\n",
    "\n",
    "    Parameters:\n",
    "        news_df (pd.DataFrame): DataFrame containing news articles.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional 'Sentiment' column.\n",
    "    \"\"\"\n",
    "    if 'content' not in news_df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'content' column for sentiment analysis.\")\n",
    "    \n",
    "    # Load the FinBERT sentiment analysis pipeline with explicit truncation\n",
    "    finbert = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"yiyanghkust/finbert-tone\",\n",
    "        tokenizer=\"yiyanghkust/finbert-tone\",\n",
    "        device=0,  # Use CPU (-1) or GPU (0 or higher)\n",
    "        truncation=True,\n",
    "        max_length=512  # Explicitly set the maximum length\n",
    "    )\n",
    "    \n",
    "    # Apply sentiment analysis to the 'content' column\n",
    "    def analyze_text(text):\n",
    "        try:\n",
    "            return finbert(text[:512])[0]['label']  # Truncate text to 512 characters\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    news_df['Sentiment'] = news_df['content'].apply(analyze_text)\n",
    "    \n",
    "    return news_df\n",
    "\n",
    "# Example usage\n",
    "api_token = API_Eodhd  # Replace with your actual API token\n",
    "stock = \"AAPL.US\"\n",
    "begin_date = \"2023-01-01\"\n",
    "end_date = \"2025-03-01\"\n",
    "tag = \"balance sheet\"\n",
    "\n",
    "# Fetch news data\n",
    "news_df = fetch_news_data(stock, tag, begin_date, end_date, api_token=api_token)\n",
    "\n",
    "# Perform sentiment analysis with FinBERT\n",
    "news_with_sentiment = analyze_sentiment_with_finbert(news_df)\n",
    "\n",
    "print(news_with_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading strategy: Use last 12 months dividends to price a stock/option\n",
    "A trading strategy where I use last 12 months dividends and price the stock/option at 6% dividend yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stock  DividendYield(%)\n",
      "0  INGA.AS              5.83\n",
      "1  ASML.AS              1.19\n"
     ]
    }
   ],
   "source": [
    "#Setting the input data\n",
    "\n",
    "def fetch_and_combine_dividend_yields(tickers_df,exchange):\n",
    "    \"\"\"\n",
    "    Fetch dividend yields for all stocks in the fullexchange_subset and combine them into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        fullexchange_subset (list or pd.Series): List of full stock tickers (e.g., [\"INGA.AS\", \"AAPL.US\"]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A combined DataFrame with all dividend yield data.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "    full_tickers = [f\"{ticker}.{exchange}\" for ticker in tickers_df]\n",
    "\n",
    "    for stock in full_tickers:\n",
    "        try:\n",
    "            # Fetch the dividend yield for the current stock\n",
    "            dividend_yield_df = Fetch_dividend_yield(stock)\n",
    "\n",
    "            # Combine the result with the existing DataFrame\n",
    "            combined_df = pd.concat([combined_df, dividend_yield_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {stock}: {e}\")\n",
    "\n",
    "    # Drop rows with missing dividend yield values\n",
    "    combined_df = combined_df.dropna(subset=[\"DividendYield(%)\"])\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# transforming the exchange symbols into a single dimensional dataframe\n",
    "def Fetch_exchange_symbols_1D(exchange_code, instrument_type=\"Common Stock\"):\n",
    "    \"\"\"\n",
    "    Fetch and transform exchange symbols into a single-dimensional DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        exchange_code (str): The code of the exchange (e.g., \"AS\").\n",
    "        instrument_type (str): The type of instrument to filter (default is \"Common Stock\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single-dimensional DataFrame containing the filtered stock codes.\n",
    "    \"\"\"\n",
    "    stock_list = fetch_exchange_symbols(exchange_code)\n",
    "    filtered_stock_list = stock_list[stock_list[\"Type\"] == instrument_type]\n",
    "    filtered_stock_list_1D = filtered_stock_list[\"Code\"]\n",
    "\n",
    "    return filtered_stock_list_1D\n",
    "\n",
    "\n",
    "'''# Example usage\n",
    "stock_list = fetch_exchange_symbols(\"AS\")\n",
    "instrument_type = \"Common Stock\"\n",
    "filtered_stock_list = stock_list[stock_list[\"Type\"] == instrument_type]\n",
    "stock2 = pd.DataFrame([fetch_exchange_symbols(\"AS\")['Code'].T])\n",
    "\n",
    "EX12 = Fetch_exchange_symbols_1D(\"AS\")\n",
    "DY12 = fetch_and_combine_dividend_yields([\"INGA\",\"ASML\"],\"AS\")\n",
    "print(DY12.dropna())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stock  DividendYield(%)\n",
      "0  INGA.AS              5.83\n",
      "1  ASML.AS              1.19\n"
     ]
    }
   ],
   "source": [
    "# Creating a theoretical value of the stock\n",
    "\n",
    "Stock_DY = fetch_and_combine_dividend_yields([\"INGA\",\"ASML\"],\"AS\")\n",
    "print(Stock_DY)\n",
    "\n",
    "Stock_LatestPrice = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
